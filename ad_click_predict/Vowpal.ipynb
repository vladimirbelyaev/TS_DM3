{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timestamp\r\n",
      "1379278800\r\n",
      "1379278800\r\n",
      "1379278800\r\n",
      "1379278800\r\n",
      "1379278800\r\n",
      "1379278800\r\n",
      "1379278800\r\n",
      "1379278800\r\n",
      "1379278800\r\n"
     ]
    }
   ],
   "source": [
    "DATADIR = \"../../pzaydel/DM3/Data/hw-ad/\"\n",
    "!head -n 10 ../../pzaydel/DM3/Data/hw-ad/train.csv | awk '{split($0,a,\";\"); print a[1]}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\r\n",
      "-1\r\n",
      "-1\r\n",
      "-1\r\n",
      "-1\r\n",
      "-1\r\n",
      "-1\r\n",
      "-1\r\n",
      "-1\r\n",
      "-1\r\n"
     ]
    }
   ],
   "source": [
    "!head ../../pzaydel/DM3/Data/hw-ad/test.csv | awk '{split($0,a,\";\"); print a[2]}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading train xgb\n",
      "Loading test xgb\n",
      "Loaded\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "COMBINEDIR = 'combine/'\n",
    "print(\"Loading train xgb\")\n",
    "train_xgb_features = np.load(COMBINEDIR + 'trainxgbfeat.npy')\n",
    "print(\"Loading test xgb\")\n",
    "test_xgb_features = np.load(COMBINEDIR + 'testxgbfeat.npy')\n",
    "print(\"Loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20317220, 30)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_xgb_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "traindata = pd.read_csv('../../pzaydel/DM3/Data/hw-ad/train.csv', sep = ';')\n",
    "testdata = pd.read_csv('../../pzaydel/DM3/Data/hw-ad/test.csv', sep = ';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainmean = traindata.label.mean()\n",
    "def fill_mean(df, feat, target_set, m):\n",
    "    mask = df[feat].apply(lambda x: x in target_set)\n",
    "    df[feat+\"_CTR\"][mask] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25bd57b5b46147dcaa4967869ab968cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=12), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C1\t0.6109284673312078\t0.7074115844652252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vbelyaev/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C2\t0.6864072194021432\t0.8068686600808858\n",
      "C3\t0.848735244519393\t0.910126582278481\n",
      "C4\t0.7113091541423425\t0.8218937246600408\n",
      "C5\t0.9795918367346939\t0.9696969696969697\n",
      "C6\t0.9448094612352168\t0.9563713753657888\n",
      "C7\t1.0\t0.75\n",
      "C8\t0.8758314855875832\t0.9316037735849056\n",
      "C9\t0.9405940594059405\t0.9405940594059405\n",
      "C10\t0.8738670694864048\t0.9315619967793881\n",
      "C11\t1.0\t1.0\n",
      "C12\t1.0\t1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm, tqdm_notebook\n",
    "import numpy as np\n",
    "for i in tqdm_notebook(range(1, 13)):\n",
    "    featname = \"C{}\".format(i)\n",
    "    a = traindata[[featname, \"label\"]].groupby(featname)[\"label\"].mean()\n",
    "    a = a.to_frame().reset_index()\n",
    "    a.columns = [a.columns[0], a.columns[0] + \"_CTR\"]\n",
    "    traindata = traindata.merge(a, left_on=featname, right_on=featname, how='left')\n",
    "    testdata = testdata.merge(a, left_on=featname, right_on=featname, how='left')\n",
    "    left_resid = set(traindata[featname].unique().tolist()) - set(testdata[featname].unique().tolist())\n",
    "    right_resid = set(testdata[featname].unique().tolist()) - set(traindata[featname].unique().tolist()) \n",
    "    val1 = len(set(testdata[featname].unique().tolist()) & set(traindata[featname].unique().tolist())) / traindata[featname].unique().shape[0]\n",
    "    val2 = len(set(testdata[featname].unique().tolist()) & set(traindata[featname].unique().tolist())) / testdata[featname].unique().shape[0]\n",
    "    print(\"{}\\t{}\\t{}\".format(featname, val1, val2))\n",
    "    fill_mean(traindata, featname, left_resid, trainmean)\n",
    "    fill_mean(testdata, featname, right_resid, trainmean)\n",
    "    del a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c50467b239c44f9984e78d48b4d77ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vbelyaev/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l1\t0.7520911803551338\t0.8783204798628963\n",
      "l2\t0.7325581395348837\t0.9130434782608695\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for l in tqdm_notebook(range(1, 3)):\n",
    "    featname = \"l{}\".format(l)\n",
    "    a = traindata[[featname, \"label\"]].groupby(featname)[\"label\"].mean()\n",
    "    a = a.to_frame().reset_index()\n",
    "    a.columns = [a.columns[0], a.columns[0] + \"_CTR\"]\n",
    "    traindata = traindata.merge(a, left_on=featname, right_on=featname, how='left')\n",
    "    testdata = testdata.merge(a, left_on=featname, right_on=featname, how='left')\n",
    "    left_resid = set(traindata[featname].unique().tolist()) - set(testdata[featname].unique().tolist())\n",
    "    right_resid = set(testdata[featname].unique().tolist()) - set(traindata[featname].unique().tolist())\n",
    "    fill_mean(traindata, featname, left_resid, trainmean)\n",
    "    fill_mean(testdata, featname, right_resid, trainmean) \n",
    "    val1 = len(set(testdata[featname].unique().tolist()) & set(traindata[featname].unique().tolist())) / traindata[featname].unique().shape[0]\n",
    "    val2 = len(set(testdata[featname].unique().tolist()) & set(traindata[featname].unique().tolist())) / testdata[featname].unique().shape[0]\n",
    "    print(\"{}\\t{}\\t{}\".format(featname, val1, val2))\n",
    "    del a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindata[\"hour\"] = (traindata.timestamp.values % (1440 * 60)) // 3600\n",
    "testdata[\"hour\"] = (testdata.timestamp.values % (1440 * 60)) // 3600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for l in [\"hour\"]:\n",
    "    featname = l\n",
    "    a = traindata[[featname, \"label\"]].groupby(featname)[\"label\"].mean()\n",
    "    a = a.to_frame().reset_index()\n",
    "    a.columns = [a.columns[0], a.columns[0] + \"_CTR\"]\n",
    "    traindata = traindata.merge(a, left_on=featname, right_on=featname, how='left')\n",
    "    testdata = testdata.merge(a, left_on=featname, right_on=featname, how='left')\n",
    "    left_resid = set(traindata[featname].unique().tolist()) - set(testdata[featname].unique().tolist())\n",
    "    right_resid = set(testdata[featname].unique().tolist()) - set(traindata[featname].unique().tolist())\n",
    "    fill_mean(traindata, featname, left_resid, trainmean)\n",
    "    fill_mean(testdata, featname, right_resid, trainmean) \n",
    "    val1 = len(set(testdata[featname].unique().tolist()) & set(traindata[featname].unique().tolist())) / traindata[featname].unique().shape[0]\n",
    "    val2 = len(set(testdata[featname].unique().tolist()) & set(traindata[featname].unique().tolist())) / testdata[featname].unique().shape[0]\n",
    "    print(\"{}\\t{}\\t{}\".format(featname, val1, val2))\n",
    "    del a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29989752/29989752 [19:25<00:00, 25729.24it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "with open(DATADIR + \"train.csv\", \"r\") as input_file, open(\"fintrain.vw\", \"w\") as output_file:\n",
    "    input_file.readline()\n",
    "    first_tmstmp = 1379278800\n",
    "    for idx, line in enumerate(tqdm(input_file, total = 29989752)):\n",
    "        features = line[:-1].split(';')\n",
    "        curr_line = \"{} |i\".format(int(features[1])*2-1)\n",
    "        # Счетчики\n",
    "        curr_line += \" l1:{} l2:{}\".format(features[15], features[16])\n",
    "        curr_line += \" |j l1_{} l2_{}\".format(features[15], features[16])\n",
    "        # Категориальные фичи\n",
    "        curr_line += \" |c\"\n",
    "        for i in range(2,5):\n",
    "            curr_line += \" C{}_{}\".format(i-1, features[i])\n",
    "        curr_line += \" |d\"\n",
    "        for i in range(5,12):\n",
    "            curr_line += \" C{}_{}\".format(i-1, features[i])\n",
    "        # Категориальные фичи: среднее\n",
    "        curr_line += \" |e\"\n",
    "        curr_line += \" C11_{}\".format(features[17])\n",
    "        curr_line += \" C12_{}\".format(features[18])\n",
    "        # Группы\n",
    "        curr_line += \" |m\"\n",
    "        curr_line += \" {}\".format(\" \".join(features[12].split(',')))\n",
    "        curr_line += \" |n\"\n",
    "        curr_line += \" {}\".format(\" \".join(features[13].split(',')))\n",
    "        curr_line += \" |k\"\n",
    "        curr_line += \" {}\".format(\" \".join(features[14].split(',')))\n",
    "        # Обработаем timestamp -> хочется посмотреть час и дату\n",
    "        timestamp = int(features[0])\n",
    "        dayseconds = timestamp % (1440 * 60)\n",
    "        dayhours = dayseconds // 3600\n",
    "        curr_line += \" |t h_{}\".format(dayhours)\n",
    "        curr_line += \" |u hr:{}\".format(dayhours)\n",
    "        #curr_line += \" |x\"\n",
    "        #for i in range(train_xgb_features.shape[1]):\n",
    "            #curr_line += \" t{}l{}\".format(i, train_xgb_features[idx, i])\n",
    "        output_file.write(curr_line + \"\\n\")\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29989752/29989752 [12:04<00:00, 41407.02it/s]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "with open(\"fintrain.vw\",'r') as source, open(\"strain\",'w') as train, open(\"stest\",'w') as test:\n",
    "    c=0\n",
    "    for line in tqdm(source, total=29989752):\n",
    "        c+=1\n",
    "        if c > 20000000:\n",
    "            test.write(line)\n",
    "        else:\n",
    "            train.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 20317220/20317221 [15:22<00:00, 22022.17it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "with open(DATADIR + \"test.csv\", \"r\") as input_file, open(\"fintest.vw\", \"w\") as output_file:\n",
    "    input_file.readline()\n",
    "    \n",
    "    for idx, line in enumerate(tqdm(input_file, total = 20317221)):\n",
    "        features = line[:-1].split(';')\n",
    "        curr_line = \"{} |i\".format(features[1])\n",
    "        # Счетчики\n",
    "        curr_line += \" l1:{} l2:{}\".format(features[15], features[16])\n",
    "        curr_line += \" |j l1_{} l2_{}\".format(features[15], features[16])\n",
    "        # Категориальные фичи\n",
    "        curr_line += \" |c\"\n",
    "        for i in range(2,5):\n",
    "            curr_line += \" C{}_{}\".format(i-1, features[i])\n",
    "        curr_line += \" |d\"\n",
    "        for i in range(5,12):\n",
    "            curr_line += \" C{}_{}\".format(i-1, features[i])\n",
    "        # Группы\n",
    "        # Категориальные фичи: среднее\n",
    "        curr_line += \" |e\"\n",
    "        curr_line += \" C11_{}\".format(features[17])\n",
    "        curr_line += \" C12_{}\".format(features[18])\n",
    "        curr_line += \" |m\"\n",
    "        curr_line += \" {}\".format(\" \".join(features[12].split(',')))\n",
    "        curr_line += \" |n\"\n",
    "        curr_line += \" {}\".format(\" \".join(features[13].split(',')))\n",
    "        curr_line += \" |k\"\n",
    "        curr_line += \" {}\".format(\" \".join(features[14].split(',')))\n",
    "        # Обработаем timestamp -> хочется посмотреть час\n",
    "        timestamp = int(features[0])\n",
    "        dayseconds = timestamp % (1440 * 60)\n",
    "        dayhours = dayseconds // 3600\n",
    "        curr_line += \" |t h_{}\".format(dayhours)\n",
    "        curr_line += \" |u hr:{}\".format(dayhours)\n",
    "        #curr_line += \" |x\"\n",
    "        #for i in range(test_xgb_features.shape[1]):\n",
    "            #curr_line += \" t{}l{}\".format(i, test_xgb_features[idx, i])\n",
    "        output_file.write(curr_line + \"\\n\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20317220it [02:06, 161232.65it/s]\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "import gzip\n",
    "curr_file = \"sample \" + str(datetime.now()).replace(\":\",\"_\").replace(\" \",\"\")[:-7]\n",
    "with open(\"fullpred124\", \"r\") as input_file, open(curr_file, 'w') as output_file:\n",
    "    output_file.write(\"Id,Click\\n\")\n",
    "    for idx, line in enumerate(tqdm(input_file)):\n",
    "        output_file.write(\"{},{}\".format(idx+1, line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "content = \"Lots of content here\"\n",
    "with gzip.open('file.txt.gz', 'wb') as f:\n",
    "    f.write(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train_data = pd.read_csv(DATADIR + 'train.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timestamp = int(\"1379279729\")\n",
    "dayseconds = timestamp % (1440 * 60)\n",
    "dayhours = dayseconds // 3600\n",
    "dayhours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1379278800 % (1440*60)//3600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
